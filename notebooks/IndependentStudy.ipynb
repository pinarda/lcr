{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a53e8e-8a7e-4d86-bfe1-900b1563a833",
   "metadata": {},
   "source": [
    "## Independent Study Final Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e8af4-040d-41c9-a45d-e442481d39e0",
   "metadata": {},
   "source": [
    "The aim of this project is to demonstrate a link between the real information content and the Bit Grooming compression level that is applied to a spatial dataset. In addition, we want to investigate how the real information performs as a metric to detect compression artifacts compared to an existing metric, the DSSIM. For instance, is there a specific real information threshold that can indicate two datasets look visually similar, as in the DSSIM? Is the real information content more effective at capturing certain types of compression induced errors in the data, such as noise?\n",
    "\n",
    "In this repository, the files /data/test_set/daily_dssims.csv and /data/test_set/monthly_dssims.csv include a list of the DSSIMS for each climate variable at each time slice, and the files /data/test_set/daily_zfp_bg_sz_comp_slices.csv and /data/test_set/monthly_zfp_bg_sz_comp_slices.csv include a column (\"zfp_level\") that provides a list of the optimal compression level for each time slice based on a DSSIM cutoff threshold of 0.9995, which may be useful for comparison with the real information content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e1768b-36a2-463b-8301-3890fa59b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ldcpy root to system path\n",
    "import sys\n",
    "import struct\n",
    "from math import log2\n",
    "\n",
    "import astropy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/apinard/newldcpy/ldcpy')\n",
    "\n",
    "# Import ldcpy package\n",
    "# Autoreloads package everytime the package is called, so changes to code will be reflected in the notebook if the above sys.path.insert(...) line is uncommented.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# suppress all of the divide by zero warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ldcpy\n",
    "\n",
    "import time\n",
    "\n",
    "# display the plots in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5511e06b-2989-44d0-a409-8ed2775b3088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUT\n",
      "dataset size in GB 1.13\n",
      "\n",
      "LHFLX\n",
      "dataset size in GB 1.13\n",
      "\n",
      "PRECT\n",
      "dataset size in GB 1.13\n",
      "\n",
      "TAUX\n",
      "dataset size in GB 1.13\n",
      "\n",
      "TS\n",
      "dataset size in GB 1.13\n",
      "\n",
      "Z500\n",
      "dataset size in GB 1.13\n",
      "\n",
      "CCN3\n",
      "dataset size in GB 2.79\n",
      "\n",
      "CLOUD\n",
      "dataset size in GB 2.79\n",
      "\n",
      "FLNS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "FLNT\n",
      "dataset size in GB 0.10\n",
      "\n",
      "FSNS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "FSNT\n",
      "dataset size in GB 0.10\n",
      "\n",
      "LHFLX\n",
      "dataset size in GB 0.10\n",
      "\n",
      "PRECC\n",
      "dataset size in GB 0.10\n",
      "\n",
      "PRECL\n",
      "dataset size in GB 0.10\n",
      "\n",
      "PS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "QFLX\n",
      "dataset size in GB 0.10\n",
      "\n",
      "SHFLX\n",
      "dataset size in GB 0.10\n",
      "\n",
      "TMQ\n",
      "dataset size in GB 0.10\n",
      "\n",
      "TS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "U\n",
      "dataset size in GB 2.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This block of code can be used to load all variables into a pair of dataset collections:\n",
    "# cols_daily and cols_monthly, which are indexed by their variable name. This data has\n",
    "# all been compressed using the Bit Grooming (bg) compression algorithm.\n",
    "\n",
    "# not including 3D variables in this case\n",
    "#monthly_variables = [\"CCN3\", \"CLOUD\", \"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "#            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\", \"U\"]\n",
    "\n",
    "monthly_variables = [\"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\"]\n",
    "daily_variables = [\"FLUT\", \"LHFLX\", \"PRECT\", \"TAUX\", \"TS\", \"Z500\"]\n",
    "\n",
    "cols_monthly = {}\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research/\"\n",
    "\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"bg_2_{variable}\",\n",
    "                        f\"bg_3_{variable}\",\n",
    "                        f\"bg_4_{variable}\", f\"bg_5_{variable}\",\n",
    "                        f\"bg_6_{variable}\", f\"bg_7_{variable}\",]\n",
    "    sets[variable] = [f\"{data_path}/../orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_2/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_3/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_4/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_5/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_6/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_7/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"]\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n",
    "for variable in monthly_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"bg_2_{variable}\",\n",
    "                        f\"bg_3_{variable}\",\n",
    "                        f\"bg_4_{variable}\", f\"bg_5_{variable}\",\n",
    "                        f\"bg_6_{variable}\", f\"bg_7_{variable}\",]\n",
    "    sets[variable] = [f\"{data_path}/../orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_2/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_3/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_4/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_5/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_6/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_7/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\"]\n",
    "    cols_monthly[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855e40b-975f-4763-8162-70f84679d410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10",
   "language": "python",
   "name": "cmip6-201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
