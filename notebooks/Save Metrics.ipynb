{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Make sure you are using the cmip6-2019.10 kernel\n",
    "\n",
    "# Add ldcpy root to system path (MODIFY FOR YOUR LDCPY CODE LOCATION)\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/apinard/newldcpy/ldcpy')\n",
    "import ldcpy\n",
    "\n",
    "# Display output of plots directly in Notebook\n",
    "%matplotlib inline\n",
    "# Automatically reload module if it is editted\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# silence warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63c24b968ab45ff804fa645a535a952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='<div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-outpu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start the dask scheduler\n",
    "\n",
    "# Note: This notebook should run on Cheyenne for now, running on casper will work for\n",
    "# the most part but trying to plot the LHFLX variable will result in a timeout,\n",
    "# presumably due to the large file sizes for the variable.\n",
    "\n",
    "# for Cheyenne\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "cluster = PBSCluster(\n",
    "    queue=\"regular\",\n",
    "    walltime=\"02:00:00\",\n",
    "    project=\"NIOW0001\",\n",
    "    memory=\"109GB\",\n",
    "    resource_spec=\"select=1:ncpus=9:mem=109GB\",\n",
    "    cores=36,\n",
    "    processes=9,\n",
    ")\n",
    "\n",
    "\n",
    "# scale as needed\n",
    "cluster.adapt(minimum_jobs=1, maximum_jobs=30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-16ceb352-8396-11ec-8048-20000b84fe80</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/apinard/proxy/{port}/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/apinard/proxy/{port}/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">da2790fb</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/apinard/proxy/{port}/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/apinard/proxy/{port}/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-80fb90bd-b11b-4618-9400-e7355dd50e5c</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.148.10.19:46137\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/apinard/proxy/{port}/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/apinard/proxy/{port}/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.148.10.19:46137' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Connect client to the remote dask workers\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUT\n",
      "dataset size in GB 1.13\n",
      "\n",
      "LHFLX\n",
      "dataset size in GB 1.13\n",
      "\n",
      "PRECT\n",
      "dataset size in GB 1.13\n",
      "\n",
      "TAUX\n",
      "dataset size in GB 1.13\n",
      "\n",
      "TS\n",
      "dataset size in GB 1.13\n",
      "\n",
      "Z500\n",
      "dataset size in GB 1.13\n",
      "\n",
      "CCN3\n",
      "dataset size in GB 2.79\n",
      "\n",
      "CLOUD\n",
      "dataset size in GB 2.79\n",
      "\n",
      "FLNS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "FLNT\n",
      "dataset size in GB 0.10\n",
      "\n",
      "FSNS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "FSNT\n",
      "dataset size in GB 0.10\n",
      "\n",
      "LHFLX\n",
      "dataset size in GB 0.10\n",
      "\n",
      "PRECC\n",
      "dataset size in GB 0.10\n",
      "\n",
      "PRECL\n",
      "dataset size in GB 0.10\n",
      "\n",
      "PS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "QFLX\n",
      "dataset size in GB 0.10\n",
      "\n",
      "SHFLX\n",
      "dataset size in GB 0.10\n",
      "\n",
      "TMQ\n",
      "dataset size in GB 0.10\n",
      "\n",
      "TS\n",
      "dataset size in GB 0.10\n",
      "\n",
      "U\n",
      "dataset size in GB 2.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cols_monthly = {}\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research/\"\n",
    "orig_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/\"\n",
    "monthly_variables = [\"CCN3\", \"CLOUD\", \"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\", \"U\"]\n",
    "daily_variables = [\"FLUT\", \"LHFLX\", \"PRECT\", \"TAUX\", \"TS\", \"Z500\"]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"bg_2_{variable}\",\n",
    "                        f\"bg_3_{variable}\",\n",
    "                        f\"bg_4_{variable}\", f\"bg_5_{variable}\",\n",
    "                        f\"bg_6_{variable}\", f\"bg_7_{variable}\",]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_2/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_3/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_4/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_5/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_6/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_7/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"]\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n",
    "for variable in monthly_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"bg_2_{variable}\",\n",
    "                        f\"bg_3_{variable}\",\n",
    "                        f\"bg_4_{variable}\", f\"bg_5_{variable}\",\n",
    "                        f\"bg_6_{variable}\", f\"bg_7_{variable}\",]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_2/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_3/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_4/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_5/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_6/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_7/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\"]\n",
    "    cols_monthly[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def save_metrics(\n",
    "    full_ds,\n",
    "    varname,\n",
    "    set1,\n",
    "    set2,\n",
    "    times=range(0,60),\n",
    "    color='coolwarm',\n",
    "    lev=0,\n",
    "    ks_tol=0.05,\n",
    "    pcc_tol=0.99999,\n",
    "    spre_tol=5.0,\n",
    "    ssim_tol=0.9995,\n",
    "    location='names.csv',\n",
    "):\n",
    "    \"\"\"\n",
    "    Check the K-S, Pearson Correlation, and Spatial Relative Error metrics from:\n",
    "    A. H. Baker, H. Xu, D. M. Hammerling, S. Li, and J. Clyne,\n",
    "    “Toward a Multi-method Approach: Lossy Data Compression for\n",
    "    Climate Simulation Data”, in J.M. Kunkel et al. (Eds.): ISC\n",
    "    High Performance Workshops 2017, Lecture Notes in Computer\n",
    "    Science 10524, pp. 30–42, 2017 (doi:10.1007/978-3-319-67630-2_3).\n",
    "    Check the SSIM metric from:\n",
    "    A.H. Baker, D.M. Hammerling, and T.L. Turton. “Evaluating image\n",
    "    quality measures to assess the impact of lossy data compression\n",
    "    applied to climate simulation data”, Computer Graphics Forum 38(3),\n",
    "    June 2019, pp. 517-528 (doi:10.1111/cgf.13707).\n",
    "    Default tolerances for the tests are:\n",
    "    ------------------------\n",
    "    K-S: fail if p-value < .05 (significance level)\n",
    "    Pearson correlation coefficient:  fail if coefficient < .99999\n",
    "    Spatial relative error: fail if > 5% of grid points fail relative error\n",
    "    SSIM: fail if SSIM < .99995\n",
    "    Parameters\n",
    "    ==========\n",
    "    ds : xarray.Dataset\n",
    "        An xarray dataset containing multiple netCDF files concatenated across a 'collection' dimension\n",
    "    varname : str\n",
    "        The variable of interest in the dataset\n",
    "    set1 : str\n",
    "        The collection label of the \"control\" data\n",
    "    set2 : str\n",
    "        The collection label of the (1st) data to compare\n",
    "    time : int, optional\n",
    "        The time index used t (default = 0)\n",
    "    ks_tol : float, optional\n",
    "        The p-value threshold (significance level) for the K-S test (default = .05)\n",
    "    pcc_tol: float, optional\n",
    "        The default Pearson corrolation coefficient (default  = .99999)\n",
    "    spre_tol: float, optional\n",
    "        The percentage threshold for failing grid points in the spatial relative error test (default = 5.0).\n",
    "    ssim_tol: float, optional\n",
    "         The threshold for the ssim test (default = .999950\n",
    "    time : lev, optional\n",
    "        The level index of interest in a 3D dataset (default 0)\n",
    "    Returns\n",
    "    =======\n",
    "    out : Number of failing metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    file_exists = os.path.isfile(location)\n",
    "    with open(location, 'a', newline='') as csvfile:\n",
    "        fieldnames = [\n",
    "            'set',\n",
    "            'time',\n",
    "            # 'max_abs',\n",
    "            # 'max_rel_error',\n",
    "            #            'pcc',\n",
    "            #            'ks_p_value',\n",
    "            #            'spatial_rel_error',\n",
    "            # 'ssim',\n",
    "            'ssim_fp',\n",
    "            # 'ssim_fp_old',\n",
    "            #            'pcc_pass',\n",
    "            #            'ks_p_value_pass',\n",
    "            #            'spatial_rel_error_pass',\n",
    "            # 'ssim_pass',\n",
    "            # 'ssim_fp_pass',\n",
    "            # 'ssim_fp_old_pass',\n",
    "        ]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        ds = ldcpy.subset_data(full_ds)\n",
    "\n",
    "        # count the number of failuress\n",
    "        num_fail = 0\n",
    "        \n",
    "        for time in times:\n",
    "            if time%10 == 0:\n",
    "                print(\n",
    "                    'Evaluating dssim for {} data (set1) and {} data (set2), time {}'.format(\n",
    "                        set1, set2, time\n",
    "                    ),\n",
    "                    ':',\n",
    "                )\n",
    "\n",
    "            diff_metrics = ldcpy.Diffcalcs(\n",
    "                ds[varname].sel(collection=set1).isel(time=time),\n",
    "                ds[varname].sel(collection=set2).isel(time=time),\n",
    "                \"cam-fv\",\n",
    "                ['lat', 'lon'],\n",
    "            )\n",
    "\n",
    "            # reg_metrics = Datasetcalcs(\n",
    "            #    ds[varname].sel(collection=set1).isel(time=time)\n",
    "            #    - ds[varname].sel(collection=set2).isel(time=time),\n",
    "            #    ['lat', 'lon'],\n",
    "            # )\n",
    "            # max_abs = reg_metrics.get_calc('max_abs').data.compute()\n",
    "\n",
    "            # max_rel_error = diff_metrics.get_diff_calc('max_spatial_rel_error')\n",
    "\n",
    "            # Pearson less than pcc_tol means fail\n",
    "            # pcc = diff_metrics.get_diff_metric('pearson_correlation_coefficient').data.compute()\n",
    "\n",
    "            # K-S p-value less than ks_tol means fail (can reject null hypo)\n",
    "            # ks = diff_metrics.get_diff_metric('ks_p_value')\n",
    "\n",
    "            # Spatial rel error fails if more than spre_tol\n",
    "            # spre = diff_metrics.get_diff_metric('spatial_rel_error')\n",
    "\n",
    "            # SSIM less than of ssim_tol is failing\n",
    "            #ssim_val = diff_metrics.get_diff_calc('ssim', color)\n",
    "\n",
    "            ssim_fp_val = diff_metrics.get_diff_calc('ssim_fp')\n",
    "\n",
    "            #ssim_fp_old_val = diff_metrics.get_diff_calc('ssim_fp_old')\n",
    "\n",
    "\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    'set': set2,\n",
    "                    'time': time,\n",
    "                    # 'max_abs': max_abs,\n",
    "                    # 'max_rel_error': max_rel_error,\n",
    "                    #                'pcc': pcc,\n",
    "                    #                'ks_p_value': ks,\n",
    "                    #                'spatial_rel_error': spre,\n",
    "                    # 'ssim': ssim_val,\n",
    "                    'ssim_fp': ssim_fp_val,\n",
    "                    # 'ssim_fp_old': ssim_fp_old_val,\n",
    "                    #                'pcc_pass': pcc >= pcc_tol,\n",
    "                    #                'ks_p_value_pass': ks >= ks_tol,\n",
    "                    #                'spatial_rel_error_pass': spre <= spre_tol,\n",
    "                    # 'ssim_pass': ssim_val >= ssim_tol,\n",
    "                    # 'ssim_fp_pass': ssim_fp_val >= ssim_tol,\n",
    "                    # 'ssim_fp_old_pass': ssim_fp_old_val >= ssim_tol,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return num_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# for variable in [\"FLNS\"]:\n",
    "#     for i in [\"bg_2\"]:\n",
    "#         save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", location=\"../data/dssims_m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dssim for orig_FLNS data (set1) and bg_2_FLNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_2_FLNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_2_FLNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_2_FLNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_2_FLNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_2_FLNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_3_FLNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_3_FLNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_3_FLNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_3_FLNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_3_FLNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_3_FLNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_4_FLNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_4_FLNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_4_FLNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_4_FLNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_4_FLNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_4_FLNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_5_FLNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_5_FLNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_5_FLNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_5_FLNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_5_FLNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_5_FLNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_6_FLNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_6_FLNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_6_FLNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_6_FLNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_6_FLNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_6_FLNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_7_FLNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_7_FLNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_7_FLNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_7_FLNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_7_FLNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNS data (set1) and bg_7_FLNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_2_FLNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_2_FLNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_2_FLNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_2_FLNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_2_FLNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_2_FLNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_3_FLNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_3_FLNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_3_FLNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_3_FLNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_3_FLNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_3_FLNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_4_FLNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_4_FLNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_4_FLNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_4_FLNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_4_FLNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_4_FLNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_5_FLNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_5_FLNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_5_FLNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_5_FLNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_5_FLNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_5_FLNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_6_FLNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_6_FLNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_6_FLNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_6_FLNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_6_FLNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_6_FLNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_7_FLNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_7_FLNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_7_FLNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_7_FLNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_7_FLNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLNT data (set1) and bg_7_FLNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_2_FSNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_2_FSNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_2_FSNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_2_FSNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_2_FSNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_2_FSNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_3_FSNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_3_FSNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_3_FSNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_3_FSNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_3_FSNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_3_FSNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_4_FSNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_4_FSNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_4_FSNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_4_FSNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_4_FSNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_4_FSNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_5_FSNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_5_FSNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_5_FSNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_5_FSNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_5_FSNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_5_FSNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_6_FSNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_6_FSNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_6_FSNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_6_FSNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_6_FSNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_6_FSNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_7_FSNS data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_7_FSNS data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_7_FSNS data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_7_FSNS data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_7_FSNS data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNS data (set1) and bg_7_FSNS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_2_FSNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_2_FSNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_2_FSNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_2_FSNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_2_FSNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_2_FSNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_3_FSNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_3_FSNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_3_FSNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_3_FSNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_3_FSNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_3_FSNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_4_FSNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_4_FSNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_4_FSNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_4_FSNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_4_FSNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_4_FSNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_5_FSNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_5_FSNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_5_FSNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_5_FSNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_5_FSNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_5_FSNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_6_FSNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_6_FSNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_6_FSNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_6_FSNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_6_FSNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_6_FSNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_7_FSNT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_7_FSNT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_7_FSNT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_7_FSNT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_7_FSNT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FSNT data (set1) and bg_7_FSNT data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_7_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_7_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_7_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_7_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_7_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_7_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_2_PRECC data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_2_PRECC data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_2_PRECC data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_2_PRECC data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_2_PRECC data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_2_PRECC data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_3_PRECC data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_3_PRECC data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_3_PRECC data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_3_PRECC data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_3_PRECC data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_3_PRECC data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_4_PRECC data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_4_PRECC data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_4_PRECC data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_4_PRECC data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_4_PRECC data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_4_PRECC data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_5_PRECC data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_5_PRECC data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_5_PRECC data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_5_PRECC data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_5_PRECC data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_5_PRECC data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_6_PRECC data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_6_PRECC data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_6_PRECC data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_6_PRECC data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_6_PRECC data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_6_PRECC data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_7_PRECC data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_7_PRECC data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_7_PRECC data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_7_PRECC data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_7_PRECC data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECC data (set1) and bg_7_PRECC data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_2_PRECL data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_2_PRECL data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_2_PRECL data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_2_PRECL data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_2_PRECL data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_2_PRECL data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_3_PRECL data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_3_PRECL data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_3_PRECL data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_3_PRECL data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_3_PRECL data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_3_PRECL data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_4_PRECL data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_4_PRECL data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_4_PRECL data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_4_PRECL data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_4_PRECL data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_4_PRECL data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_5_PRECL data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_5_PRECL data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_5_PRECL data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_5_PRECL data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_5_PRECL data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_5_PRECL data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_6_PRECL data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_6_PRECL data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_6_PRECL data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_6_PRECL data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_6_PRECL data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_6_PRECL data (set2), time 50 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_7_PRECL data (set2), time 0 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_7_PRECL data (set2), time 10 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_7_PRECL data (set2), time 20 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_7_PRECL data (set2), time 30 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_7_PRECL data (set2), time 40 :\n",
      "Evaluating dssim for orig_PRECL data (set1) and bg_7_PRECL data (set2), time 50 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_2_PS data (set2), time 0 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_2_PS data (set2), time 10 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_2_PS data (set2), time 20 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_2_PS data (set2), time 30 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_2_PS data (set2), time 40 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_2_PS data (set2), time 50 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_3_PS data (set2), time 0 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_3_PS data (set2), time 10 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_3_PS data (set2), time 20 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_3_PS data (set2), time 30 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_3_PS data (set2), time 40 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_3_PS data (set2), time 50 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_4_PS data (set2), time 0 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_4_PS data (set2), time 10 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_4_PS data (set2), time 20 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_4_PS data (set2), time 30 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_4_PS data (set2), time 40 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_4_PS data (set2), time 50 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_5_PS data (set2), time 0 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_5_PS data (set2), time 10 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_5_PS data (set2), time 20 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_5_PS data (set2), time 30 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_5_PS data (set2), time 40 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_5_PS data (set2), time 50 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_6_PS data (set2), time 0 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_6_PS data (set2), time 10 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_6_PS data (set2), time 20 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_6_PS data (set2), time 30 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_6_PS data (set2), time 40 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_6_PS data (set2), time 50 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_7_PS data (set2), time 0 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_7_PS data (set2), time 10 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_7_PS data (set2), time 20 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_7_PS data (set2), time 30 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_7_PS data (set2), time 40 :\n",
      "Evaluating dssim for orig_PS data (set1) and bg_7_PS data (set2), time 50 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_2_QFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_2_QFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_2_QFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_2_QFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_2_QFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_2_QFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_3_QFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_3_QFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_3_QFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_3_QFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_3_QFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_3_QFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_4_QFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_4_QFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_4_QFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_4_QFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_4_QFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_4_QFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_5_QFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_5_QFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_5_QFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_5_QFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_5_QFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_5_QFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_6_QFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_6_QFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_6_QFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_6_QFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_6_QFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_6_QFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_7_QFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_7_QFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_7_QFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_7_QFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_7_QFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_QFLX data (set1) and bg_7_QFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_2_SHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_2_SHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_2_SHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_2_SHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_2_SHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_2_SHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_3_SHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_3_SHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_3_SHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_3_SHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_3_SHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_3_SHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_4_SHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_4_SHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_4_SHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_4_SHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_4_SHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_4_SHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_5_SHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_5_SHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_5_SHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_5_SHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_5_SHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_5_SHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_6_SHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_6_SHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_6_SHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_6_SHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_6_SHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_6_SHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_7_SHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_7_SHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_7_SHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_7_SHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_7_SHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_SHFLX data (set1) and bg_7_SHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_2_TMQ data (set2), time 0 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_2_TMQ data (set2), time 10 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_2_TMQ data (set2), time 20 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_2_TMQ data (set2), time 30 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_2_TMQ data (set2), time 40 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_2_TMQ data (set2), time 50 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_3_TMQ data (set2), time 0 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_3_TMQ data (set2), time 10 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_3_TMQ data (set2), time 20 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_3_TMQ data (set2), time 30 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_3_TMQ data (set2), time 40 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_3_TMQ data (set2), time 50 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_4_TMQ data (set2), time 0 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_4_TMQ data (set2), time 10 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_4_TMQ data (set2), time 20 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_4_TMQ data (set2), time 30 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_4_TMQ data (set2), time 40 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_4_TMQ data (set2), time 50 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_5_TMQ data (set2), time 0 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_5_TMQ data (set2), time 10 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_5_TMQ data (set2), time 20 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_5_TMQ data (set2), time 30 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_5_TMQ data (set2), time 40 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_5_TMQ data (set2), time 50 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_6_TMQ data (set2), time 0 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_6_TMQ data (set2), time 10 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_6_TMQ data (set2), time 20 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_6_TMQ data (set2), time 30 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_6_TMQ data (set2), time 40 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_6_TMQ data (set2), time 50 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_7_TMQ data (set2), time 0 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_7_TMQ data (set2), time 10 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_7_TMQ data (set2), time 20 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_7_TMQ data (set2), time 30 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_7_TMQ data (set2), time 40 :\n",
      "Evaluating dssim for orig_TMQ data (set1) and bg_7_TMQ data (set2), time 50 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_2_TS data (set2), time 0 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_2_TS data (set2), time 10 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_2_TS data (set2), time 20 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_2_TS data (set2), time 30 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_2_TS data (set2), time 40 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_2_TS data (set2), time 50 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_3_TS data (set2), time 0 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_3_TS data (set2), time 10 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_3_TS data (set2), time 20 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_3_TS data (set2), time 30 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_3_TS data (set2), time 40 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_3_TS data (set2), time 50 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_4_TS data (set2), time 0 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_4_TS data (set2), time 10 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_4_TS data (set2), time 20 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_4_TS data (set2), time 30 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_4_TS data (set2), time 40 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_4_TS data (set2), time 50 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_5_TS data (set2), time 0 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_5_TS data (set2), time 10 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_5_TS data (set2), time 20 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_5_TS data (set2), time 30 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_5_TS data (set2), time 40 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_5_TS data (set2), time 50 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_6_TS data (set2), time 0 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_6_TS data (set2), time 10 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_6_TS data (set2), time 20 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_6_TS data (set2), time 30 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_6_TS data (set2), time 40 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_6_TS data (set2), time 50 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_7_TS data (set2), time 0 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_7_TS data (set2), time 10 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_7_TS data (set2), time 20 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_7_TS data (set2), time 30 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_7_TS data (set2), time 40 :\n",
      "Evaluating dssim for orig_TS data (set1) and bg_7_TS data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_2_FLUT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_2_FLUT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_2_FLUT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_2_FLUT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_2_FLUT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_2_FLUT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_3_FLUT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_3_FLUT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_3_FLUT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_3_FLUT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_3_FLUT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_3_FLUT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_4_FLUT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_4_FLUT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_4_FLUT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_4_FLUT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_4_FLUT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_4_FLUT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_5_FLUT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_5_FLUT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_5_FLUT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_5_FLUT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_5_FLUT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_5_FLUT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_6_FLUT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_6_FLUT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_6_FLUT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_6_FLUT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_6_FLUT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_6_FLUT data (set2), time 50 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_7_FLUT data (set2), time 0 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_7_FLUT data (set2), time 10 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_7_FLUT data (set2), time 20 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_7_FLUT data (set2), time 30 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_7_FLUT data (set2), time 40 :\n",
      "Evaluating dssim for orig_FLUT data (set1) and bg_7_FLUT data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_2_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_3_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_4_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 0 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 10 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 20 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 30 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 40 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_5_LHFLX data (set2), time 50 :\n",
      "Evaluating dssim for orig_LHFLX data (set1) and bg_6_LHFLX data (set2), time 0 :\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "for variable in [\"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\"]:\n",
    "    for i in [\"bg_2\", \"bg_3\", \"bg_4\", \"bg_5\", \"bg_6\", \"bg_7\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", location=\"../data/dssims_m.csv\")\n",
    "\n",
    "for variable in daily_variables:\n",
    "    for i in [\"bg_2\", \"bg_3\", \"bg_4\", \"bg_5\", \"bg_6\", \"bg_7\"]:\n",
    "        save_metrics(cols_daily[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", location=\"../data/dssims_d.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for variable in [\"CCN3\", \"CLOUD\", \"U\"]:\n",
    "    for i in [\"bg_2\", \"bg_3\", \"bg_4\", \"bg_5\", \"bg_6\", \"bg_7\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_3m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rerun on zfp\n",
    "import time\n",
    "\n",
    "cols_monthly = {}\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research/\"\n",
    "monthly_variables = [\"CCN3\", \"CLOUD\", \"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\", \"U\"]\n",
    "daily_variables = [\"FLUT\", \"LHFLX\", \"PRECT\", \"TAUX\", \"TS\", \"Z500\"]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"zfp_p_8_{variable}\",\n",
    "                        f\"zfp_p_10_{variable}\",\n",
    "                        f\"zfp_p_12_{variable}\", f\"zfp_p_14_{variable}\",\n",
    "                        f\"zfp_p_16_{variable}\", f\"zfp_p_18_{variable}\", f\"zfp_p_20_{variable}\",\n",
    "                        f\"zfp_p_22_{variable}\", f\"zfp_p_24_{variable}\"]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_8/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_10/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_12/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_14/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_16/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_18/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_20/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_22/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_24/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"]\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n",
    "for variable in monthly_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"zfp_p_8_{variable}\",\n",
    "                        f\"zfp_p_10_{variable}\",\n",
    "                        f\"zfp_p_12_{variable}\", f\"zfp_p_14_{variable}\",\n",
    "                        f\"zfp_p_16_{variable}\", f\"zfp_p_18_{variable}\", f\"zfp_p_20_{variable}\",\n",
    "                        f\"zfp_p_22_{variable}\", f\"zfp_p_24_{variable}\"]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_8/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_10/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_12/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_14/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_16/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_18/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_20/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_22/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/zfp_all/zfp_p_24/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\"]\n",
    "    cols_monthly[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for zfp again\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "for variable in [\"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "           \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\"]:\n",
    "    for i in [\"zfp_p_8\", \"zfp_p_10\", \"zfp_p_12\", \"zfp_p_14\", \"zfp_p_16\", \"zfp_p_18\", \"zfp_p_20\", \"zfp_p_22\", \"zfp_p_24\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_m.csv\")\n",
    "\n",
    "for variable in daily_variables:\n",
    "    for i in [\"zfp_p_8\", \"zfp_p_10\", \"zfp_p_12\", \"zfp_p_14\", \"zfp_p_16\", \"zfp_p_18\", \"zfp_p_20\", \"zfp_p_22\", \"zfp_p_24\"]:\n",
    "        save_metrics(cols_daily[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_d.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for variable in [\"CCN3\", \"CLOUD\", \"U\"]:\n",
    "    for i in [\"zfp_p_8\", \"zfp_p_10\", \"zfp_p_12\", \"zfp_p_14\", \"zfp_p_16\", \"zfp_p_18\", \"zfp_p_20\", \"zfp_p_22\", \"zfp_p_24\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_3m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Rerun on sz 1.4\n",
    "import time\n",
    "\n",
    "cols_monthly = {}\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research/\"\n",
    "monthly_variables = [\"CCN3\", \"CLOUD\", \"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\", \"U\"]\n",
    "daily_variables = [\"FLUT\", \"LHFLX\", \"PRECT\", \"TAUX\", \"TS\", \"Z500\"]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"sz1.4_1_{variable}\",\n",
    "                        f\"sz1.4_05_{variable}\",\n",
    "                        f\"sz1.4_01_{variable}\", f\"sz1.4_005_{variable}\",\n",
    "                        f\"sz1.4_001_{variable}\", f\"sz1.4_0005_{variable}\", f\"sz1.4_0001_{variable}\",\n",
    "                        f\"sz1.4_00005_{variable}\", f\"sz1.4_00001_{variable}\",\n",
    "                        f\"sz1.4_000005_{variable}\", f\"sz1.4_000001_{variable}\"]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.1/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.01/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.0005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.0001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn5e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn1e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn5e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn1e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"]\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n",
    "for variable in monthly_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"sz1.4_1_{variable}\",\n",
    "                        f\"sz1.4_05_{variable}\",\n",
    "                        f\"sz1.4_01_{variable}\", f\"sz1.4_005_{variable}\",\n",
    "                        f\"sz1.4_001_{variable}\", f\"sz1.4_0005_{variable}\", f\"sz1.4_0001_{variable}\",\n",
    "                        f\"sz1.4_00005_{variable}\", f\"sz1.4_00001_{variable}\",\n",
    "                        f\"sz1.4_000005_{variable}\", f\"sz1.4_000001_{variable}\"]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.1/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.01/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.0005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn0.0001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn5e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn1e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn5e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz1.4/sz2_1_12ROn1e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\"]\n",
    "    cols_monthly[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This one is for sz 1.4\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "for variable in [\"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\"]:\n",
    "    for i in [f\"sz1.4_1\", f\"sz1.4_05\", f\"sz1.4_01\", f\"sz1.4_005\",\n",
    "              f\"sz1.4_001\", f\"sz1.4_0005\", f\"sz1.4_0001\", f\"sz1.4_00005\",\n",
    "              f\"sz1.4_00001\", f\"sz1.4_000005\", f\"sz1.4_000001\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_m.csv\")\n",
    "\n",
    "for variable in daily_variables:\n",
    "    for i in [f\"sz1.4_1\", f\"sz1.4_05\", f\"sz1.4_01\", f\"sz1.4_005\",\n",
    "          f\"sz1.4_001\", f\"sz1.4_0005\", f\"sz1.4_0001\", f\"sz1.4_00005\",\n",
    "          f\"sz1.4_00001\", f\"sz1.4_000005\", f\"sz1.4_000001\"]:\n",
    "        save_metrics(cols_daily[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_d.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for variable in [\"CLOUD\", \"CCN3\", \"U\"]:\n",
    "    for i in [f\"sz1.4_1\", f\"sz1.4_05\", f\"sz1.4_01\", f\"sz1.4_005\",\n",
    "              f\"sz1.4_001\", f\"sz1.4_0005\", f\"sz1.4_0001\", f\"sz1.4_00005\",\n",
    "              f\"sz1.4_00001\", f\"sz1.4_000005\", f\"sz1.4_000001\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_3m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Rerun on sz 1.4\n",
    "import time\n",
    "\n",
    "cols_monthly = {}\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/research/\"\n",
    "monthly_variables = [\"CCN3\", \"CLOUD\", \"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\", \"U\"]\n",
    "daily_variables = [\"FLUT\", \"LHFLX\", \"PRECT\", \"TAUX\", \"TS\", \"Z500\"]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"sz2.1_1_{variable}\",\n",
    "                        f\"sz2.1_05_{variable}\",\n",
    "                        f\"sz2.1_01_{variable}\", f\"sz2.1_005_{variable}\",\n",
    "                        f\"sz2.1_001_{variable}\", f\"sz2.1_0005_{variable}\", f\"sz2.1_0001_{variable}\",\n",
    "                        f\"sz2.1_00005_{variable}\", f\"sz2.1_00001_{variable}\",\n",
    "                        f\"sz2.1_000005_{variable}\", f\"sz2.1_000001_{variable}\"]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.1/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.01/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.0005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.0001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn5e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn1e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn5e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn1e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"]\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n",
    "for variable in monthly_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"sz2.1_1_{variable}\",\n",
    "                        f\"sz2.1_05_{variable}\",\n",
    "                        f\"sz2.1_01_{variable}\", f\"sz2.1_005_{variable}\",\n",
    "                        f\"sz2.1_001_{variable}\", f\"sz2.1_0005_{variable}\", f\"sz2.1_0001_{variable}\",\n",
    "                        f\"sz2.1_00005_{variable}\", f\"sz2.1_00001_{variable}\",\n",
    "                        f\"sz2.1_000005_{variable}\", f\"sz2.1_000001_{variable}\"]\n",
    "    sets[variable] = [f\"{orig_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.1/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.01/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.0005/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn0.0001/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn5e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn1e-05/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn5e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/sz2.1.12/sz2_1_12ROn1e-06/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\"]\n",
    "    cols_monthly[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one is for sz 1.4\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "for variable in [\"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\"]:\n",
    "    for i in [f\"sz2.1_1\", f\"sz2.1_05\", f\"sz2.1_01\", f\"sz2.1_005\",\n",
    "              f\"sz2.1_001\", f\"sz2.1_0005\", f\"sz2.1_0001\", f\"sz2.1_00005\",\n",
    "              f\"sz2.1_00001\", f\"sz2.1_000005\", f\"sz2.1_000001\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_m.csv\")\n",
    "\n",
    "for variable in daily_variables:\n",
    "    for i in [f\"sz2.1_1\", f\"sz2.1_05\", f\"sz2.1_01\", f\"sz2.1_005\",\n",
    "          f\"sz2.1_001\", f\"sz2.1_0005\", f\"sz2.1_0001\", f\"sz2.1_00005\",\n",
    "          f\"sz2.1_00001\", f\"sz2.1_000005\", f\"sz2.1_000001\"]:\n",
    "        save_metrics(cols_daily[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_d.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in [\"CLOUD\", \"CCN3\", \"U\"]:\n",
    "    for i in [f\"sz2.1_1\", f\"sz2.1_05\", f\"sz2.1_01\", f\"sz2.1_005\",\n",
    "              f\"sz2.1_001\", f\"sz2.1_0005\", f\"sz2.1_0001\", f\"sz2.1_00005\",\n",
    "              f\"sz2.1_00001\", f\"sz2.1_000005\", f\"sz2.1_000001\"]:\n",
    "        save_metrics(cols_monthly[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", time=time, location=\"../data/dssims_3m.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10",
   "language": "python",
   "name": "cmip6-201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
