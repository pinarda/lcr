{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you are using the cmip6-2019.10 kernel\n",
    "\n",
    "# Add ldcpy root to system path (MODIFY FOR YOUR LDCPY CODE LOCATION)\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/apinard/newldcpy/ldcpy')\n",
    "import ldcpy\n",
    "\n",
    "# Display output of plots directly in Notebook\n",
    "%matplotlib inline\n",
    "# Automatically reload module if it is editted\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# silence warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the dask scheduler\n",
    "\n",
    "# Note: This notebook should run on Cheyenne for now, running on casper will work for\n",
    "# the most part but trying to plot the LHFLX variable will result in a timeout,\n",
    "# presumably due to the large file sizes for the variable.\n",
    "\n",
    "# for Cheyenne\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "cluster = PBSCluster(\n",
    "    queue=\"regular\",\n",
    "    walltime=\"02:00:00\",\n",
    "    project=\"NIOW0001\",\n",
    "    memory=\"109GB\",\n",
    "    resource_spec=\"select=1:ncpus=9:mem=109GB\",\n",
    "    cores=36,\n",
    "    processes=9,\n",
    ")\n",
    "\n",
    "\n",
    "# scale as needed\n",
    "cluster.adapt(minimum_jobs=1, maximum_jobs=30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Connect client to the remote dask workers\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "cols_monthly = {}\n",
    "cols_daily = {}\n",
    "sets = {}\n",
    "levels = {}\n",
    "data_path = \"/glade/p/cisl/asap/CAM_lossy_test_data_31/\"\n",
    "monthly_variables = [\"CCN3\", \"CLOUD\", \"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\", \"U\"]\n",
    "daily_variables = [\"FLUT\", \"LHFLX\", \"PRECT\", \"TAUX\", \"TS\", \"Z500\"]\n",
    "\n",
    "for variable in daily_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"bg_2_{variable}\",\n",
    "                        f\"bg_3_{variable}\",\n",
    "                        f\"bg_4_{variable}\", f\"bg_5_{variable}\",\n",
    "                        f\"bg_6_{variable}\", f\"bg_7_{variable}\",]\n",
    "    sets[variable] = [f\"{data_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_2/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_3/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_4/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_5/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_6/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\",\n",
    "                      f\"{data_path}/bg/bg_7/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h1.{variable}.20060101-20071231.nc\"]\n",
    "    cols_daily[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n",
    "for variable in monthly_variables:\n",
    "    print(variable)\n",
    "    levels[variable] = [f\"bg_2_{variable}\",\n",
    "                        f\"bg_3_{variable}\",\n",
    "                        f\"bg_4_{variable}\", f\"bg_5_{variable}\",\n",
    "                        f\"bg_6_{variable}\", f\"bg_7_{variable}\",]\n",
    "    sets[variable] = [f\"{data_path}/orig/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_2/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_3/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_4/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_5/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_6/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\",\n",
    "                      f\"{data_path}/bg/bg_7/b.e11.BRCP85C5CNBDRD.f09_g16.031.cam.h0.{variable}.200601-201012.nc\"]\n",
    "    cols_monthly[variable] = ldcpy.open_datasets(\"cam-fv\", [f\"{variable}\"], sets[variable], [f\"orig_{variable}\"] + levels[variable], chunks={\"time\":700})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(\n",
    "    full_ds,\n",
    "    varname,\n",
    "    set1,\n",
    "    set2,\n",
    "    times=range(0,60),\n",
    "    color='coolwarm',\n",
    "    lev=0,\n",
    "    ks_tol=0.05,\n",
    "    pcc_tol=0.99999,\n",
    "    spre_tol=5.0,\n",
    "    ssim_tol=0.9995,\n",
    "    location='names.csv',\n",
    "):\n",
    "    \"\"\"\n",
    "    Check the K-S, Pearson Correlation, and Spatial Relative Error metrics from:\n",
    "    A. H. Baker, H. Xu, D. M. Hammerling, S. Li, and J. Clyne,\n",
    "    “Toward a Multi-method Approach: Lossy Data Compression for\n",
    "    Climate Simulation Data”, in J.M. Kunkel et al. (Eds.): ISC\n",
    "    High Performance Workshops 2017, Lecture Notes in Computer\n",
    "    Science 10524, pp. 30–42, 2017 (doi:10.1007/978-3-319-67630-2_3).\n",
    "    Check the SSIM metric from:\n",
    "    A.H. Baker, D.M. Hammerling, and T.L. Turton. “Evaluating image\n",
    "    quality measures to assess the impact of lossy data compression\n",
    "    applied to climate simulation data”, Computer Graphics Forum 38(3),\n",
    "    June 2019, pp. 517-528 (doi:10.1111/cgf.13707).\n",
    "    Default tolerances for the tests are:\n",
    "    ------------------------\n",
    "    K-S: fail if p-value < .05 (significance level)\n",
    "    Pearson correlation coefficient:  fail if coefficient < .99999\n",
    "    Spatial relative error: fail if > 5% of grid points fail relative error\n",
    "    SSIM: fail if SSIM < .99995\n",
    "    Parameters\n",
    "    ==========\n",
    "    ds : xarray.Dataset\n",
    "        An xarray dataset containing multiple netCDF files concatenated across a 'collection' dimension\n",
    "    varname : str\n",
    "        The variable of interest in the dataset\n",
    "    set1 : str\n",
    "        The collection label of the \"control\" data\n",
    "    set2 : str\n",
    "        The collection label of the (1st) data to compare\n",
    "    time : int, optional\n",
    "        The time index used t (default = 0)\n",
    "    ks_tol : float, optional\n",
    "        The p-value threshold (significance level) for the K-S test (default = .05)\n",
    "    pcc_tol: float, optional\n",
    "        The default Pearson corrolation coefficient (default  = .99999)\n",
    "    spre_tol: float, optional\n",
    "        The percentage threshold for failing grid points in the spatial relative error test (default = 5.0).\n",
    "    ssim_tol: float, optional\n",
    "         The threshold for the ssim test (default = .999950\n",
    "    time : lev, optional\n",
    "        The level index of interest in a 3D dataset (default 0)\n",
    "    Returns\n",
    "    =======\n",
    "    out : Number of failing metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    file_exists = os.path.isfile(location)\n",
    "        with open(location, 'a', newline='') as csvfile:\n",
    "            fieldnames = [\n",
    "                'set',\n",
    "                'time',\n",
    "                # 'max_abs',\n",
    "                # 'max_rel_error',\n",
    "                #            'pcc',\n",
    "                #            'ks_p_value',\n",
    "                #            'spatial_rel_error',\n",
    "                # 'ssim',\n",
    "                'ssim_fp',\n",
    "                # 'ssim_fp_old',\n",
    "                #            'pcc_pass',\n",
    "                #            'ks_p_value_pass',\n",
    "                #            'spatial_rel_error_pass',\n",
    "                # 'ssim_pass',\n",
    "                # 'ssim_fp_pass',\n",
    "                # 'ssim_fp_old_pass',\n",
    "            ]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "    \n",
    "    for time in times:\n",
    "\n",
    "        ds = subset_data(full_ds)\n",
    "\n",
    "        # count the number of failuress\n",
    "        num_fail = 0\n",
    "\n",
    "        print(\n",
    "            'Evaluating 4 metrics for {} data (set1) and {} data (set2), time {}'.format(\n",
    "                set1, set2, time\n",
    "            ),\n",
    "            ':',\n",
    "        )\n",
    "\n",
    "        diff_metrics = Diffcalcs(\n",
    "            ds[varname].sel(collection=set1).isel(time=time),\n",
    "            ds[varname].sel(collection=set2).isel(time=time),\n",
    "            ['lat', 'lon'],\n",
    "        )\n",
    "\n",
    "        # reg_metrics = Datasetcalcs(\n",
    "        #    ds[varname].sel(collection=set1).isel(time=time)\n",
    "        #    - ds[varname].sel(collection=set2).isel(time=time),\n",
    "        #    ['lat', 'lon'],\n",
    "        # )\n",
    "        # max_abs = reg_metrics.get_calc('max_abs').data.compute()\n",
    "\n",
    "        # max_rel_error = diff_metrics.get_diff_calc('max_spatial_rel_error')\n",
    "\n",
    "        # Pearson less than pcc_tol means fail\n",
    "        # pcc = diff_metrics.get_diff_metric('pearson_correlation_coefficient').data.compute()\n",
    "\n",
    "        # K-S p-value less than ks_tol means fail (can reject null hypo)\n",
    "        # ks = diff_metrics.get_diff_metric('ks_p_value')\n",
    "\n",
    "        # Spatial rel error fails if more than spre_tol\n",
    "        # spre = diff_metrics.get_diff_metric('spatial_rel_error')\n",
    "\n",
    "        # SSIM less than of ssim_tol is failing\n",
    "        ssim_val = diff_metrics.get_diff_calc('ssim', color)\n",
    "\n",
    "        ssim_fp_val = diff_metrics.get_diff_calc('ssim_fp')\n",
    "\n",
    "        ssim_fp_old_val = diff_metrics.get_diff_calc('ssim_fp_old')\n",
    "\n",
    "        \n",
    "            writer.writerow(\n",
    "                {\n",
    "                    'set': set2,\n",
    "                    'time': time,\n",
    "                    # 'max_abs': max_abs,\n",
    "                    # 'max_rel_error': max_rel_error,\n",
    "                    #                'pcc': pcc,\n",
    "                    #                'ks_p_value': ks,\n",
    "                    #                'spatial_rel_error': spre,\n",
    "                    # 'ssim': ssim_val,\n",
    "                    'ssim_fp': ssim_fp_val,\n",
    "                    # 'ssim_fp_old': ssim_fp_old_val,\n",
    "                    #                'pcc_pass': pcc >= pcc_tol,\n",
    "                    #                'ks_p_value_pass': ks >= ks_tol,\n",
    "                    #                'spatial_rel_error_pass': spre <= spre_tol,\n",
    "                    # 'ssim_pass': ssim_val >= ssim_tol,\n",
    "                    # 'ssim_fp_pass': ssim_fp_val >= ssim_tol,\n",
    "                    # 'ssim_fp_old_pass': ssim_fp_old_val >= ssim_tol,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return num_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "for variable in [\"FLNS\", \"FLNT\", \"FSNS\", \"FSNT\", \"LHFLX\",\n",
    "            \"PRECC\", \"PRECL\", \"PS\", \"QFLX\", \"SHFLX\", \"TMQ\", \"TS\"]:\n",
    "    for time in range(0,cols_monthly[variable].dims[\"time\"]):\n",
    "        for i in [\"bg_2\", \"bg_3\", \"bg_4\", \"bg_5\", \"bg_6\", \"bg_7\"]:\n",
    "            ldcpy.save_metrics(cols[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", location=\"../data/dssims.csv\")\n",
    "\n",
    "for variable in daily_variables:\n",
    "    for time in range(0,cols_daily[variable].dims[\"time\"]):\n",
    "        for i in [\"bg_2\", \"bg_3\", \"bg_4\", \"bg_5\", \"bg_6\", \"bg_7\"]:\n",
    "            ldcpy.save_metrics(cols[variable], variable, f\"orig_{variable}\", f\"{i}_{variable}\", location=\"../data/dssims.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
